name: Actualizar resultados lotería

on:
  schedule:
    - cron: "*/10 * * * *"          # cada 10 minutos
  workflow_dispatch:

concurrency:
  group: scraper-production
  cancel-in-progress: false

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Instalar dependencias Python (incluye Playwright)
        run: |
          set -euxo pipefail
          python -V
          pip install --upgrade pip
          pip install playwright beautifulsoup4 requests google-auth google-auth-httplib2 google-auth-oauthlib
          if [ -f scraper/requirements.txt ]; then pip install -r scraper/requirements.txt; fi

      - name: Instalar Playwright + Chromium
        run: |
          set -euxo pipefail
          python -m playwright install --with-deps chromium

      - name: Ejecutar tu scraper (Playwright con Xvfb) + FCM por secret
        env:
          TZ: "America/Santo_Domingo"
          FCM_SERVICE_ACCOUNT_JSON: ${{ secrets.FCM_SERVICE_ACCOUNT_JSON }}
        run: |
          set -euxo pipefail
          xvfb-run -a python scraper/main.py
          ls -la
          echo "Scraper terminado."

      - name: Publicar HOY desde TU JSON ORIGINAL (sin modificar datos) y desactivar Jekyll
        run: |
          python - << 'PY'
          import json, pathlib, datetime, zoneinfo
          TZ = zoneinfo.ZoneInfo("America/Santo_Domingo")
          def hoy_str(): return datetime.datetime.now(TZ).date().isoformat()

          root_json = pathlib.Path("resultados_combinados.json")
          orig_json = pathlib.Path("scraper/data/resultados_combinados.json")
          src = None
          if orig_json.exists() and root_json.exists():
              src = orig_json if orig_json.stat().st_mtime >= root_json.stat().st_mtime else root_json
          elif orig_json.exists():
              src = orig_json
          elif root_json.exists():
              src = root_json

          outdir = pathlib.Path("docs"); outdir.mkdir(parents=True, exist_ok=True)
          (outdir / ".nojekyll").write_text("", encoding="utf-8")

          if not src:
              payload = {"generado": datetime.datetime.utcnow().isoformat()+"Z", "resultados":[]}
              (outdir/"resultados.json").write_text(json.dumps(payload, separators=(",",":")), encoding="utf-8")
              (outdir/"status.json").write_text(json.dumps({
                  "ok": False, "message": "Sin datos del scraper",
                  "generated_at_utc": payload["generado"]
              }, separators=(",",":")), encoding="utf-8")
              print("No se encontró resultados_combinados.json")
              raise SystemExit(0)

          # Sincroniza histórico en ambas rutas (por si tu script solo escribió en una)
          data = json.loads(src.read_text(encoding="utf-8"))
          for target in (root_json, orig_json):
              target.parent.mkdir(parents=True, exist_ok=True)
              target.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

          # Publica SOLO HOY tal cual (sin tocar nombres ni números)
          items = data if isinstance(data, list) else data.get("resultados", [])
          hoy = hoy_str()
          solo_hoy = [
              {k: v for k, v in it.items() if k in ("loteria","numeros","fecha")}
              for it in items if str(it.get("fecha","")) == hoy
          ]

          payload = {"generado": datetime.datetime.utcnow().isoformat()+"Z", "resultados": solo_hoy}
          (outdir/"resultados.json").write_text(json.dumps(payload, ensure_ascii=False, separators=(",",":")), encoding="utf-8")
          (outdir/"status.json").write_text(json.dumps({
              "ok": True, "message": f"HOY {hoy}: {len(solo_hoy)} resultados",
              "generated_at_utc": payload["generado"]
          }, separators=(",",":")), encoding="utf-8")
          print(f"Publicados HOY {hoy}: {len(solo_hoy)}")
          PY

      - name: Subir artefactos de depuración (por si algo sale raro)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: debug-scrape
          path: |
            resultados_combinados.json
            scraper/data/resultados_combinados.json
            debug_*.html
          if-no-files-found: ignore

      - name: Commit & push si hubo cambios (JSON, status y .nojekyll)
        run: |
          set -euxo pipefail

          # Config git
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --global --add safe.directory "$GITHUB_WORKSPACE"

          # Stage de salidas
          git add docs/resultados.json docs/status.json docs/.nojekyll \
                  resultados_combinados.json scraper/data/resultados_combinados.json || true

          # Commit solo si hay cambios
          if git diff --cached --quiet; then
            echo "Nada que commitear"
            exit 0
          fi
          git commit -m "chore: actualizar feed ($(date -u +'%Y-%m-%dT%H:%M:%SZ'))"

          # --- Rama local real y rebase sobre origin/main (evita detached HEAD y non-fast-forward) ---
          git fetch origin main
          git checkout -B auto-pages   # crea/actualiza rama local apuntando al commit recién hecho

          # Preferimos rebase; si falla, hacemos merge sin editar mensaje
          if ! git rebase origin/main; then
            git rebase --abort || true
            git merge --no-edit origin/main || true
          fi

          # Push con lease (seguro). Si otro run movió el remoto entre rebase y push, reintentamos una vez.
          if ! git push --force-with-lease origin auto-pages:main; then
            git fetch origin main
            if ! git rebase origin/main; then
              git rebase --abort || true
              git merge --no-edit origin/main || true
            fi
            git push --force-with-lease origin auto-pages:main
          fi

      - name: Marcar error en status.json (si falla)
        if: failure()
        run: |
          python - << 'PY'
          import json, datetime, pathlib
          outdir = pathlib.Path("docs"); outdir.mkdir(parents=True, exist_ok=True)
          (outdir / ".nojekyll").write_text("", encoding="utf-8")
          (outdir/"status.json").write_text(json.dumps({
              "ok": False,
              "message": "Fallo en scraper/normalización o push",
              "generated_at_utc": datetime.datetime.utcnow().isoformat()+"Z"
          }, separators=(",",":")), encoding="utf-8")
          PY
